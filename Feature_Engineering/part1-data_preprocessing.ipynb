{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用IRIS数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据集的四个特征名称\n",
    "# 1.花萼长度\n",
    "# 2.花萼宽度\n",
    "# 3.花瓣长度\n",
    "# 4.花瓣宽度\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据集的目标名称\n",
    "# 0.山鸢尾\n",
    "# 1.杂色鸢尾\n",
    "# 2.维吉尼亚鸢尾\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 详细数据,查看前10\n",
    "iris.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分类数据,已经用OneHot编码标志好,\n",
    "iris.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.数据预处理\n",
    "## 使用sklearn的数据处理酷preprocessing进行数据的预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 标准化（将数据调整为正态分布，去均值的中心化（均值变为0）；方差的规模化（方差变为1）：\n",
    "$$\\acute{x} = \\frac{x-\\bar{x}}{S} ,\\bar{x}:为均值, S：为方差$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SS = StandardScaler()   # 因为StandardScaler是一个Class,所以先要实例化\n",
    "SS_data = SS.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.03205722, -1.3412724 , -1.31297673],\n",
       "       [-1.14301691, -0.1249576 , -1.3412724 , -1.31297673],\n",
       "       [-1.38535265,  0.33784833, -1.39813811, -1.31297673],\n",
       "       [-1.50652052,  0.10644536, -1.2844067 , -1.31297673],\n",
       "       [-1.02184904,  1.26346019, -1.3412724 , -1.31297673],\n",
       "       [-0.53717756,  1.95766909, -1.17067529, -1.05003079],\n",
       "       [-1.50652052,  0.80065426, -1.3412724 , -1.18150376],\n",
       "       [-1.02184904,  0.80065426, -1.2844067 , -1.31297673],\n",
       "       [-1.74885626, -0.35636057, -1.3412724 , -1.31297673],\n",
       "       [-1.14301691,  0.10644536, -1.2844067 , -1.4444497 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SS_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2区间规模化，这里规模到[0,1]的范围：\n",
    "$$\\acute{x} = \\frac{x-Min}{Max-Min},Max为样本某一特征的最大值，Min为样本某以特征的最小值$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "mm_data = mm.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 正则化Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "nor = Normalizer() # 默认norm='l2'，l2正则化\n",
    "no_data = nor.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 二值化\n",
    "#### 即设定某个阈值，当某个样本的某个特征值大于这个阈值的时候，设为1，小于等于这个阈值的时候则为0\n",
    "#### 这个也经常用在预测类别的时候使用，当confidence> 0.5的时候就为1，confidence <= 0.5 则为0\n",
    "公式：\n",
    "$$\\acute{x} = \\begin{cases}1,x > threshold\\\\ 0, x <= threshold \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# 这里仅作示范，我随便设置了threshold=0.5,真实情况还是要具体观察数据的量纲规格\n",
    "Bin = Binarizer(threshold=0.5)\n",
    "Bin_data = Bin.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 独热编码OneHotEncoder\n",
    "假设x1样本对应于类别y1=0, 任务里具有的类别数目为3种类别，则经过OneHotEncoder之后，y1=[1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot = OneHotEncoder()\n",
    "true_class = one_hot.fit_transform(iris.target.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 缺失值处理\n",
    "对于一些大型数据集，会存在不少样本的某些特征值是缺失的，缺失的数据会对模型的训练造成不好的影响。因此我们需要进行缺失值的填补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import nan, array\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# 创建一个具有nan的array以作示范\n",
    "a = array([[1, 1.3, 2.3, 3],\n",
    "           [1.4, 1.5, 2.0, 3.3],\n",
    "    [nan, nan, nan, nan]])\n",
    "im = Imputer(strategy='mean')  # 默认与mean均值方式进行填补，也可以选择中位数，众数等方式进行填补\n",
    "a = im.fit_transform(a, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4, 1.5, 2. , 3.3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
