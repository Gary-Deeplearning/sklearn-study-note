{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征选择(Feature-Selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Filter Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 方差(variance)选择法\n",
    "#### 方差：在概率学里，方差是衡量随机变量或一组数据的离散程度，值越大，离散程度越大。\n",
    "那么在数据分析/机器学习中，某个特征的数据的方差值越小，则说明这个值的离散程度很小，变化程度小，因此有很多大概率对target的影响没那么大，因此可以选择舍弃此特征。相反，如果方差值越大，则说明特征值在不同样本里的变化程度也大，有很大概率对target有很大的详细程度，应保留。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# 设定阈值threshold,方差大于阈值，则选择\n",
    "VT = VarianceThreshold(threshold=3)\n",
    "vt_data = VT.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从下面值可以看出，特征选择之后，只保留了一个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape, vt_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 相关系数法(Pearson)\n",
    "#### 相关系数法：计算各个特征值对target值的相关系数的pearson值，局限性是pearson相关系数计算的结果是线性关系，公式为：\n",
    "$$ r=\\frac{N\\sum x_iy_i - \\sum x_i \\sum y_i}{\\sqrt{N\\sum x_i^2-(\\sum x_i)^2} \\sqrt{N\\sum y_i^2-(\\sum yi)^2}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest  # 移除得分前K名以外的特征，即只保留TopK的特征\n",
    "from scipy.stats import pearsonr   # scipy.stats.pearsonr库里计算的pearson相关系数\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 创建一个计算多个特征的pearson系数的函数\n",
    "def multiFeature_pearsonr(X, y):\n",
    "    '''\n",
    "    params: X: 输入特征\n",
    "            y: 输入标签\n",
    "    '''\n",
    "    scores, p_values = [], []\n",
    "    for ret in map(lambda x:pearsonr(x, y), X.T):\n",
    "        scores.append(abs(ret[0]))\n",
    "        p_values.append(ret[1])\n",
    "    \n",
    "    return (np.array(scores), np.array(p_values))\n",
    "\n",
    "sk = SelectKBest(score_func=multiFeature_pearsonr, k=2)  # 选择top2\n",
    "x_pearson = sk.fit_transform(iris.data, iris.target)   # 会自动调用multiFeature_pearsonr(X, y)函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pearson.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 卡方检验方法(chi-square test method)\n",
    "#### 卡方检验：该方法就是检验定性自变量对因变量的相关性。假设自变量有N种取值，因变量有M种取值，考虑自变量等于i且因变量等于j的样本频数的观察值与期望的差距，构建统计量：\n",
    "$$ x^2 = \\sum{\\frac{(A-E)^2}{E}}=\\sum_{i=1}^{k}\\frac{(A_i-E_i)^2}{E_i}=\\sum_{i=1}^{k}\\frac{(A_i-np_i)^2}{np_i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "sk_chi2 = SelectKBest(score_func=chi2, k=2)\n",
    "chi2_data = sk_chi2.fit_transform(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 互信息法\n",
    "#### 互信息法：也是检验自变量与因变量的相关性的，互信息计算公式为：\n",
    "$$ I(X;Y)=\\sum_{x\\in{X}} \\sum_{y\\in{Y}}p(x,y)\\log{p(x,y)/p(x)p(y)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "sk_mi = SelectKBest(mutual_info_classif, k=2)\n",
    "mi_data = sk_mi.fit_transform(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
